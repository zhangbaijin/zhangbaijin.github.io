<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.0 Transitional//EN">
<HTML xml:lang="en" xmlns="http://www.w3.org/1999/xhtml">
<META name=GENERATOR content="MSHTML 11.00.9600.17280"></HEAD>
<META name=keywords 
content="Xiaofeng Zhang, Xiaofeng Zhang, Xiaofeng Zhang, zhang Xiaofeng, xiaofengzhang, zhangxiaofeng, 张晓峰, sjtu, SJTU, Shang Hai Jiao Tong Unversity">
<META 
content="IE=7.0000" http-equiv="X-UA-Compatible">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <link rel="stylesheet" href="./jemdoc.css" type="text/css">
    <title>Xiaofeng Zhang's Homepage</title>
</head>



<body data-feedly-mini="yes">

<div id="layout-content" style="margin-top:25px">

<table>
    <tbody>
        <tr>
            <td width="670" >
                <div id="toptitle">                 
                    <h1> Xiaofeng Zhang (张晓峰) &nbsp; </h1><h1> <!-- <img src="./contents/portrait.jpg" width="190" style="margin-bottom:-10px"> -->
                </h1></div>

                <h3>Ph.D student, SJTU
                </h3></div> 
                <br>
                <br>
                <p>
                   Key Laboratory of System Control and Information Processing
                    <br>
                    <br>
                         Shang Hai Jiao Tong Unversity</a>
                    <br>
                    <br>
                    Email: framebreak@sjtu.edu.cn, 微信: SemiZxf
                    <br>
                    <br>
<!--                     <font color="#FF0000">Currently on the job market! Seeking faculty/job opportunities (begin in 2026 Summer/Fall)!</font> -->
                    <br>
                    <br>
                    [<a href="https://scholar.google.co.jp/citations?hl=zh-CN&user=Y6Z5xQQAAAAJ">Google Scholar</a>]
                    [<a href="https://github.com/zhangbaijin">GitHub</a>]
                  
                
                </p>
            </td>
            <td rowspan="1">
                <img src="./images/zxf-marry.jpg" border="0" width="300" align="bottom" ><br>
            </td>
        </tr>
                <!-- <br> -->
                <!-- <colgroup><col height="50" width="270">
                </colgroup> -->
                <!-- <tbody> -->
                <td align="bottom" colspan="2" style="margin-top:2px">
                    <h2>News</h2>
                    <div style="height: 150px; overflow: auto;">
                    <ul style="margin-left:2px; padding-left:20px; margin-top:5px">
                        
                        <li>10/2024: We introduce <a href="https://arxiv.org/html/2406.06579v3">LLaVA-CAM</a>, From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning Tasks!</li>
                        <li>12/2024: I have one paper accepted by <a href="https://aaai.org/conference/aaai/aaai-25/"> AAAI 2025</a>. </li>
                        <li>10/2024: I have one paper accepted by <a href="https://wacv2025.thecvf.com/"> WACV 2025</a>. </li>
                        <li>09/2024: I have one paper accepted by <a href="https://neurips.cc/Conferences/2024/"> NIPS 2024</a>. </li>
                        <li>08/2024: I have one paper accepted by <a href="https://2024.acmmm.org/"> ACM MM 2024</a>. </li>
                        <li>08/2024: I have one paper accepted by <a href="https://bmvc2024.org/"> BMVC 2024</a>. </li>
                        <li>01/2024: We have three paper accepted by <a href="https://2024.ieeeicassp.org/"> ICASSP 2024</a>. </li>
<!--                         <li>07/2023: I have one paper accepted by <a href="https://www.acmmm2023.org/"> ACM MM 2023</a>. </li>
                        <li>07/2023: I have one paper accepted by <a href="https://iccv2023.thecvf.com/"> ICCV 2023</a>. See you at Paris! </li>
                        <li>07/2023: I have a new homepage. </li> -->
                    </ul>
                    </div>
                </td>
            

        </tbody>
</table>

<h2>About Me</h2>
<p>
    I am currently an Ph.D student at SJTU</a>,  <a href="https://iwin.sjtu.edu.cn///"> Shang Hai Jiao Tong University </a>, working with Prof. <a href="https://automation.sjtu.edu.cn/Chao-Chen/">Chaochen Gu</a> and Prof. <a href="https://cs.pku.edu.cn/info/1082/3208.htm/">Hao Tang</a>. Prior to that, I received my bachelor degree in NJUPT</a>. My current research focuses on large vision-language models. 
</p> 
    

<h2>Biography</h2>

<li> 2024.01 - Present, Research Intern at Alibaba Groud(飞天实验室), supervised by <a href="https://scholar.google.co.jp/citations?user=b6vn1uMAAAAJ&hl=zh-CN/">Chen Shen</a>.

<li> 2022.09 - Present, Ph.D at Shang Hai Jiao Tong Unversity.
    
<li> 2021.09 - 2022.9. Product manger. in China Mobile Communications Group Jiangsu Co., LTD. Wuxi branch.

<li> 2014.09- 2021.06, B/M.Eng. in Nanjing University of Posts and Telecommunications</a>


</tbody></table>


 
<h2>Preprints </a>  </h2> 
    <table id="Preprints" width="100%">


<!--     <tr>
        <td width="300">
        <img src="./images/seeing.jpg" width="260px" height="120px">
        </td>
        <td>
        <p> Seeing Clearly by Layer Two: Enhancing Attention Heads to Alleviate Hallucination in LVLMs </a></p>
        <p><b>Xiaofeng Zhang</b>, Yihao Quan, Chaochen Gu, Chen Shen, Xiaosong Yuan, Shaotian Yan, Jieping Ye</p>
        [<a href="https://arxiv.org/html/2411.09968v1">arXiv</a>]

    </tr> 
    <tr><td>   <br>  </td></tr> --> -->

        
        
    <tr>
        <td width="300">
        <img src="./images/naacl.jpg" width="260px" height="120px">
        </td>
        <td>
        <p> From Redundancy to Relevance: Information Flow in LVLMs Across Reasoning Tasks </a></p>
        <p><b>Xiaofeng Zhang</b>, Yihao Quan, Chen Shen, Xiaosong Yuan, Shaotian Yan, Chaochen Gu, Hao Tang, Jieping Ye</p>
        [<a href="https://arxiv.org/html/2406.06579v3">arXiv</a>]
        [<a href="https://github.com/zhangbaijin/From-Redundancy-to-Relevance">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

        <tr>
        <td width="300">
        <img src="./images/memorynet.jpg" width="260px" height="120px">
        </td>
        <td>
        <p> Memory augment is All You Need for image restoration </a></p>
        <p><b>Xiaofeng Zhang</b>, Chaochen Gu, Shanying Zhu</p>
        [<a href="https://arxiv.org/abs/2309.01377">arXiv</a>]
        [<a href="https://github.com/zhangbaijin/MemoryNet">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

</tbody></table>


<h2>Publications </a>  </h2> 
<table id="tbPublications" width="100%">
    <tbody>
   <tr>
        <td width="300">
        <img src="./images/simignore.jpg" width="260px" height="120px">
        </td>
        <td>
        <p>Enhancing Multimodal Large Language Models Complex Reasoning via Similarity Computation </a></p>
        <p><b>Xiaofeng Zhang</b>, Fanshuo Zeng, Yihao Quan, Zheng Hui, Jiawei Yao</p>
        <p><i>AAAI, 2025. </i> </p>
        [<a href="https://github.com/FanshuoZeng/Simignore">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

        
    <tr>
        <td width="300">
        <img src="./images/mm.jpg" width="260px" height="120px">
        </td>
        <td>
        <p> DOPRA: Decoding Over-accumulation Penalization and Re-allocation in Specific Weighting Layer </a></p>
        <p>Jingfeng Wei*, <b>Xiaofeng Zhang*</b></p>
        <p><i>ACM MM, 2024. </i> </p>
        [<a href="https://arxiv.org/abs/2407.15130">arXiv</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

    <tr>    
        <td width="300">
            <img src="./images/wacv.jpg" width="260px" height="120px">
            </td>
            <td>
        <p> High-Fidelity Document Stain Removal via A Large-Scale Real-World Dataset and A Memory-Augmented Transformer  </a></p>
        <p>Mingxian Li, Hao Sun, Yingtie Lei,<b>Xiaofeng Zhang</b>, Yihang Dong, Yilin Zhou, Zimeng Li, Xuhang Chen</p>
        <p><i>WACV, 2024. </i></p>
        [<a href="https://arxiv.org/abs/2410.22922">arXiv</a>]
        [<a href="https://github.com/CXH-Research/StainRestorer">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>
        
    <tr>
            <td width="300">
            <img src="./images/nips.jpg" width="260px" height="120px">
            </td>
            <td>
            <p> Instance-adaptive Zero-shot Chain-of-Thought Prompting</a></p>
            <p>Xiaosong Yuan, Chen Shen, Shaotian Yan, <b>Xiaofeng Zhang</b>, Liang Xie, Wenxiao Wang, Renchu Guan, Ying Wang, Jieping Ye</p>
            <p><i>NeurIPS, 2024. </i></p>
            [<a href="https://arxiv.org/abs/2409.20441">arXiv</a>]

    </tr> 
    <tr><td>   <br>  </td></tr>

    <tr>
            <td width="300">
            <img src="./images/tomm.jpg" width="260px" height="120px">
            </td>
            <td>
            <p>Wakeup-Darkness: When Multimodal Meets Unsupervised Low-light Image Enhancement</a></p>
            <p><b>Xiaofeng Zhang</b>, Zishan Xu, Hao Tang, Chaochen Gu, Wei Chen</p>
            <p><i>ACM Transactions on Multimedia Computing, Communications(<b>TOMM</b>), 2024. </i></p>
            [<a href="https://ieeexplore.ieee.org/document/10440368">arXiv</a>]
            [<a href="https://github.com/zhangbaijin/Wakeup-Darkness">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

      <tr>
            <td width="300">
            <img src="./images/bmvc.jpg" width="260px" height="120px">
            </td>
            <td>
            <p>Improving depth gradient continuity in transformers: A comparative study on monocular depth estimation with cnn</a></p>
            <p>Jiawei Yao, Tong Wu,<b>Xiaofeng Zhang</b></p>
            <p><i>BMVC, 2024. </i></p>
            [<a href="https://arxiv.org/abs/2308.08333">arXiv</a>]
            [<a href="https://github.com/Jiawei-Yao0812/PixelFormer_DGR">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>



    <tr>
            <td width="300">
            <img src="./images/tetci.jpg" width="260px" height="120px">
            </td>
            <td>
            <p> MuralDiff:Diffusion for Ancient Murals restoration on Large-scale Pre-training</a></p>
            <p>Zishan Xu,<b>Xiaofeng Zhang</b>, Wei Chen, Jueting Liu, Tingting Xu, Zehua Wang</p>
            <p><i>IEEE Transactions on Emerging Topics in Computational Intelligence(<b>TETCI</b>), 2024. </i></p>
            [<a href="https://ieeexplore.ieee.org/document/10440368">arXiv</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

 <tr>
            <td width="300">
            <img src="./images/iconip.jpg" width="260px" height="120px">
            </td>
            <td>
            <p>Retinexmamba: Retinex-based Mamba for Low-light Image Enhancement</a></p>
            <p>Jiesong Bai, Yuhao Yin, Qiyuan He, Yuanxian Li, <b>Xiaofeng Zhang</b>,</p>
            <p><i>ICONIP, 2024. </i></p>
            [<a href="hhttps://arxiv.org/pdf/2405.03349">arXiv</a>]
            [<a href="https://github.com/YhuoyuH/RetinexMamba">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>
    
    <tr>
            <td width="300">
            <img src="./images/spa-former.jpg" width="260px" height="120px">
            </td>
            <td>
            <p> SpA-Former: An Effective and lightweight Transformer for image shadow removal </a></p>
            <p><b>Xiaofeng Zhang</b>, Yudi Zhao, Chaochen Gu</p>
            <p><i>International Joint Conference on Neural Networks, (<b>IJCNN</b>), 2023. </i></p>
            [<a href="https://ieeexplore.ieee.org/document/10191081">arXiv</a>]
            [<a href="https://github.com/zhangbaijin/SpA-Former-shadow-removal">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

    <tr>
            <td width="300">
            <img src="./images/spl.jpg" width="260px" height="120px">
            </td>
            <td>
            <p>Sienet: Siamese expansion network for image extrapolation</a></p>
            <p><b>Xiaofeng Zhang</b>, Feng Chen, Cailing Wang</p>
            <p><i>IEEE Signal Processing Letters (<b>SPL</b>), 2021. </i></p>
            [<a href="https://arxiv.org/abs/2007.03851">Paper</a>]
     [<a href="https://github.com/nanjingxiaobawang/SieNet-Image-extrapolation">Code</a>]
    </tr> 
    <tr><td>   <br>  </td></tr>

 
</tbody></table>


<h2>Awards</h2>
<table id="Awards" border="0" width="100%">

    <tbody>

    <li> 2021 National Scholarship</a> 


<tr><td>   <br>  </td></tr>


</tbody></table>

<h2>Services</h2>
<table id="Services" border="0" width="100%">

    <tbody>


<br>
<br>

Invited Reviewer for: 
    <li> TIP, TETCI
    <li> CVPR, ICLR, IJCAI, IJCNN


<tr><td>   <br>  </td></tr>

</tbody></table>


</body>
</html>
